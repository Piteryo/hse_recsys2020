{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR(pair-wise loss) на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP(list-wise loss) на implicit данных\n",
    "\n",
    "Мягкий дедлайн 28 Сентября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 5 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from scipy.sparse import random\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.sparse\n",
    "\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       5\n",
       "1        1       661       3\n",
       "2        1       914       3\n",
       "3        1      3408       4\n",
       "4        1      2355       5\n",
       "5        1      1197       3\n",
       "6        1      1287       5\n",
       "7        1      2804       5\n",
       "8        1       594       4\n",
       "9        1       919       4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating\n",
       "0         1      1193       5\n",
       "3         1      3408       4\n",
       "4         1      2355       5\n",
       "6         1      1287       5\n",
       "7         1      2804       5\n",
       "8         1       594       4\n",
       "9         1       919       4\n",
       "10        1       595       5\n",
       "11        1       938       4\n",
       "12        1      2398       4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def recommend(self, user_id, user_item_csr, n=10): \n",
    "        user_emb = self.user_factors[user_id]\n",
    "        predicted_rating = user_emb.dot(self.item_factors.T)\n",
    "        user_hist = user_item_csr[user_id]\n",
    "        hist_size = user_hist.count_nonzero()\n",
    "        top_preds = np.argsort(predicted_rating)[-(n + hist_size + 1):]\n",
    "        new_recs = np.setdiff1d(top_preds, user_hist.nonzero()[1])\n",
    "        return np.flip(new_recs[-n:]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ratings[\"user_id\"]\n",
    "movies = ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((ratings[\"rating\"], (users, movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD(MF):\n",
    "    def __init__(self, lr=0.02, lamb=1e-2, feat_num=76, num_epochs=1):\n",
    "        self.lr = lr\n",
    "        self.lamb = lamb\n",
    "        self.feat_num = feat_num\n",
    "        self.num_epochs = num_epochs\n",
    "        \n",
    "    def fit(self, user_item, ratings):\n",
    "        self.user_factors = np.random.uniform(0, 1/np.sqrt(self.feat_num), (user_item.shape[0], self.feat_num))\n",
    "        self.item_factors = np.random.uniform(0, 1/np.sqrt(self.feat_num), (self.feat_num, user_item.shape[1]))\n",
    "        \n",
    "        B_w = np.random.normal(0, 1, (user_item.shape[0]))\n",
    "        B_h = np.random.normal(0, 1, (user_item.shape[1]))\n",
    "\n",
    "        gen_bias = np.mean(ratings)\n",
    "        for _ in tqdm(range(self.num_epochs)):\n",
    "            for i, j, v in zip(tqdm(user_item.row, leave=False,), user_item.col, user_item.data):\n",
    "                error = (self.user_factors[i, :] @ self.item_factors[:, j] + B_w[i] +  B_h[j] + gen_bias) - v\n",
    "                W_i_old = self.user_factors[i, :].copy()\n",
    "                B_w[i] -= self.lr * (error + self.lamb * B_w[i])\n",
    "                B_h[j] -= self.lr * (error + self.lamb * B_h[j])\n",
    "                self.user_factors[i, :] -= self.lr * (error * self.item_factors[:, j].T + self.lamb * (self.user_factors[i, :] + B_w[i]))\n",
    "                self.item_factors[:, j] -= self.lr * (error * W_i_old.T + self.lamb * (self.item_factors[:, j] + B_h[j]))\n",
    "            print(mean_squared_error((self.user_factors @ self.item_factors + B_w.reshape(-1, 1) + B_h.reshape(1, -1) + gen_bias)[user_item.row, user_item.col], user_item.data))\n",
    "        self.item_factors = self.item_factors.T\n",
    "        return self\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5bacf5deaa4e1eaa180b0ebba60c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000209.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075691424076567\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sg = sg.fit(user_item, ratings['rating'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1179    Princess Bride, The (1987)',\n",
       " '1132    Wrong Trousers, The (1993)',\n",
       " '735    Close Shave, A (1995)',\n",
       " '148    Apollo 13 (1995)',\n",
       " '315    Shawshank Redemption, The (1994)',\n",
       " '1222    Glory (1989)',\n",
       " '1242    Great Escape, The (1963)']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars_items = lambda item_id, sim : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                        for x in reversed(np.argsort(sim[item_id,:])[-10:])]\n",
    "\n",
    "get_similars_items(1, cosine_similarity(sg.item_factors.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1913    Halloween (1978)',\n",
       " '1324    Carrie (1976)',\n",
       " '1326    Nightmare on Elm Street, A (1984)',\n",
       " '1114    Howling, The (1980)',\n",
       " '2292    Pink Flamingos (1972)',\n",
       " '2593    War of the Worlds, The (1953)',\n",
       " '956    Night of the Living Dead (1968)',\n",
       " '1329    Omen, The (1976)',\n",
       " '2390    Texas Chainsaw Massacre, The (1974)',\n",
       " '1925    Poltergeist (1982)']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_similars_items(1982, cosine_similarity(H.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2559    Star Wars: Episode I - The Phantom Menace (1999)',\n",
       " '3249    Deterrence (1998)',\n",
       " '877    1-900 (1994)',\n",
       " '3159    Wirey Spindell (1999)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '675    Tigrero: A Film That Was Never Made (1994)',\n",
       " '2468    Beyond the Poseidon Adventure (1979)',\n",
       " '345    Clear and Present Danger (1994)',\n",
       " '2412    My Name Is Joe (1998)',\n",
       " '2182    Cabinet of Dr. Ramirez, The (1991)']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "get_similars_items(2628, cosine_similarity(H.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3724    X-Men (2000)',\n",
       " '3406    Place in the Sun, A (1951)',\n",
       " '3013    World Is Not Enough, The (1999)',\n",
       " '2970    Trading Places (1983)',\n",
       " '2964    Spaceballs (1987)',\n",
       " '2951    Falling Down (1993)',\n",
       " '2020    Rescuers Down Under, The (1990)',\n",
       " '2019    Popeye (1980)',\n",
       " '2012    Little Mermaid, The (1989)',\n",
       " '2011    Lady and the Tramp (1955)']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так и не получилось подобрать классные параметры для SGD :(\n",
    "Но все равно вроде рекоммендации +- адекватны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS:\n",
    "    def __init__(self, lamb, n_iters, n_factors, alpha):\n",
    "        self.lamb = lamb\n",
    "        self.alpha = alpha\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def fit(self, ratings):\n",
    "        #У нас спарс матрицы - единички просто так не прибавить, попробуем это сделать в другом месте\n",
    "        Cui = ratings.copy().tocsr()\n",
    "        Cui.data *= self.alpha\n",
    "        Ciu = Cui.T.tocsr()\n",
    "        self.n_users, self.n_items = Cui.shape\n",
    "\n",
    "        rstate = np.random.RandomState(228)\n",
    "        self.W = scipy.sparse.csr_matrix(rstate.normal(size = (self.n_users, self.n_factors)))\n",
    "        self.H = scipy.sparse.csr_matrix(rstate.normal(size = (self.n_items, self.n_factors)))\n",
    "        \n",
    "        for _ in trange(self.n_iters, desc = 'training'):\n",
    "            self._als_step(Cui, self.W, self.H, self.n_users)\n",
    "            self._als_step(Ciu, self.H, self.W, self.n_items)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _als_step(self, Cui, X, Y, n_shag):\n",
    "        YtY = Y.T.dot(Y)\n",
    "        Y_eye = scipy.sparse.eye(Y.shape[0])\n",
    "        lambda_eye = self.lamb * scipy.sparse.eye(self.n_factors)\n",
    "        for u in tqdm(range(n_shag)):\n",
    "            conf_samp = Cui[u,:].toarray()\n",
    "            pref = conf_samp.copy()\n",
    "            pref[pref != 0] = 1\n",
    "            cui_loc = scipy.sparse.diags(conf_samp, [0])\n",
    "            A = YtY + Y.T.dot(cui_loc).dot(Y)+lambda_eye\n",
    "            b = Y.T.dot(cui_loc+Y_eye).dot(pref.T)\n",
    "            \n",
    "            X[u] = spsolve(A, b)\n",
    "\n",
    "        return self\n",
    "als = ALS(n_iters = 15, n_factors = 64, alpha = 15, lamb = 0.01)\n",
    "als.fit(user_item_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, sim : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string()\n",
    "                                        for x in reversed(np.argsort(sim[item_id,:])[-10:])]\n",
    "\n",
    "get_similars(1, cosine_similarity(als.H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_similars = lambda item_id, sim : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string()\n",
    "                                        for x in reversed(np.argsort(sim[item_id,:])[-10:])]\n",
    "\n",
    "get_similars(2628, cosine_similarity(als.H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если что, у меня уже здесь были норм рекоммендации, вы мне поставили 25, можете посмотреть прошлый коммит, я просто случайно затер, а переобучить уже не успевал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(MF):\n",
    "    def __init__(self, n_factors=100, lr=0.1, lamb=0.1):\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.lamb = lamb\n",
    "        \n",
    "    \n",
    "    def fit(self, user_item_csr, n_epochs=15):\n",
    "        self.n_users, self.n_items = user_item_csr.shape\n",
    "        self.user_factors = np.random.normal(0., 1./np.sqrt(self.n_factors),\n",
    "                                             size=(self.n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(0., 1./np.sqrt(self.n_factors),\n",
    "                                             size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        self.zero_rows = (user_item_csr.getnnz(1) == 0).nonzero()[0]\n",
    "        for epoch in trange(n_epochs):\n",
    "            rows, cols = user_item_csr.nonzero()\n",
    "            loss = 0.\n",
    "            for user_id, pos_item_id in zip(tqdm(rows), cols):\n",
    "                neg_item_id = np.random.randint(1, self.n_items)\n",
    "                while user_item_csr[user_id, neg_item_id] > 0:\n",
    "                    neg_item_id = np.random.randint(1, self.n_items)\n",
    "                \n",
    "                user_u = self.user_factors[user_id]\n",
    "                item_i = self.item_factors[pos_item_id]\n",
    "                item_j = self.item_factors[neg_item_id]\n",
    "                \n",
    "                r_ui = user_u.dot(item_i.T)\n",
    "                r_uj = user_u.dot(item_j.T)\n",
    "                r_uij = r_ui - r_uj\n",
    "\n",
    "                sigmoid = np.exp(-r_uij) / (1. + np.exp(-r_uij))\n",
    "            \n",
    "                self.user_factors[user_id] -= self.lr * (sigmoid * (self.item_factors[neg_item_id] - self.item_factors[pos_item_id]) + self.lamb * self.user_factors[user_id])\n",
    "                self.item_factors[pos_item_id] -= self.lr * (sigmoid * (-self.user_factors[user_id]) + self.lamb * self.item_factors[pos_item_id])\n",
    "                self.item_factors[neg_item_id] -= self.lr * (sigmoid * self.user_factors[user_id] + self.lamb * self.item_factors[neg_item_id])\n",
    "                loss += np.log(sigmoid)\n",
    "\n",
    "            \n",
    "            loss /= len(rows)\n",
    "            print(f'Cur loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c12ababf6447c69e53fd50e8b3a94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 1/6 [00:37<03:09, 37.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -1.7650790420643565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d23916636af4976a621264b2072725f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 2/6 [01:17<02:34, 38.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -3.4272270219319645\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd134c831789415b9bf3ba81455a2ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 3/6 [01:57<01:56, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -4.328069878948879\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4cd968fa4a445987fc78f9f9c1859d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 4/6 [02:35<01:17, 38.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -4.907923534845171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab46b3d120846939d3d6dd7929fa59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 5/6 [03:16<00:39, 39.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -5.520148785874685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365ef614b63146f4b3ba989a9e895a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=575281.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:54<00:00, 39.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cur loss: -6.2325779187190715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bpr_model = BPR(n_factors=64, lr=0.07, lamb=0.000001)\n",
    "bpr_model.fit(user_item_csr, n_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '3682    Chicken Run (2000)',\n",
       " '2252    Pleasantville (1998)',\n",
       " '584    Aladdin (1992)',\n",
       " '1250    Back to the Future (1985)',\n",
       " '1838    Mulan (1998)',\n",
       " '360    Lion King, The (1994)',\n",
       " '591    Beauty and the Beast (1991)']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars = lambda item_id, sim : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string()\n",
    "                                        for x in reversed(np.argsort(sim[item_id,:])[-10:])]\n",
    "\n",
    "get_similars(1, cosine_similarity(bpr_model.item_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3509    Gladiator (2000)',\n",
       " '3352    Animal House (1978)',\n",
       " '2879    From Russia with Love (1963)',\n",
       " '1931    Lethal Weapon (1987)',\n",
       " '1353    Star Trek: The Wrath of Khan (1982)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '1239    Stand by Me (1986)',\n",
       " '1230    Bridge on the River Kwai, The (1957)',\n",
       " '1203    Godfather: Part II, The (1974)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, bpr_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно поподбирать параметры и немного улучшить результаты, естественно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WARP(MF):\n",
    "    def __init__(self, n_factors=100, lr=0.1, lamb=0.1):\n",
    "        self.n_factors = n_factors\n",
    "        self.lr = lr\n",
    "        self.lamb = lamb\n",
    "        self.M = 1\n",
    "        self.max_negatives = 10\n",
    "    \n",
    "    \n",
    "    def fit(self, user_item_csr, n_epochs=15):\n",
    "        self.n_users, self.n_items = user_item_csr.shape\n",
    "        self.user_factors = np.random.uniform(0., 1./np.sqrt(self.n_factors),\n",
    "                                             size=(self.n_users, self.n_factors))\n",
    "        self.item_factors = np.random.uniform(0., 1./np.sqrt(self.n_factors),\n",
    "                                             size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        self.zero_rows = (user_item_csr.getnnz(1) == 0).nonzero()[0]\n",
    "        for epoch in trange(n_epochs):\n",
    "            rows, cols = user_item_csr.nonzero()\n",
    "            sum_loss = 0.\n",
    "            for user_id, pos_item_id in zip(tqdm(rows), cols):\n",
    "                score_pos = self.user_factors[user_id].dot(self.item_factors[pos_item_id])\n",
    "                for n in range(1, self.max_negatives + 1):\n",
    "                    neg_item_id = np.random.randint(1, self.n_items)\n",
    "                    while user_item_csr[user_id, neg_item_id] > 0:\n",
    "                        neg_item_id = np.random.randint(1, self.n_items)\n",
    "                        \n",
    "                    score_neg = self.user_factors[user_id].dot(self.item_factors[neg_item_id])\n",
    "                    if self.M + score_neg - score_pos > 0:\n",
    "                        rank_approx = self.max_negatives / n\n",
    "                        rank_loss = np.log(rank_approx)\n",
    "                        loss = rank_loss #(self.M + score_neg - score_pos)\n",
    "\n",
    "                        self.user_factors[user_id] -= self.lr * (rank_loss * (self.item_factors[neg_item_id] - self.item_factors[pos_item_id]) + self.lamb * self.user_factors[user_id])\n",
    "                        self.item_factors[pos_item_id] -= self.lr * (rank_loss * (-self.user_factors[user_id]) + self.lamb * self.item_factors[pos_item_id])\n",
    "                        self.item_factors[neg_item_id] -= self.lr * (rank_loss * self.user_factors[user_id] + self.lamb * self.item_factors[neg_item_id])\n",
    "                        sum_loss += loss\n",
    "                        \n",
    "                        break\n",
    "\n",
    "            \n",
    "            sum_loss /= len(rows)\n",
    "            print(f'Cur loss: {sum_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "warp_model = WARP(n_factors=64, lr=0.02, lamb=0.0000001)\n",
    "\n",
    "warp_model.fit(user_item_csr, n_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2559    Star Wars: Episode I - The Phantom Menace (1999)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '1192    Star Wars: Episode VI - Return of the Jedi (1983)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1335    Star Trek: First Contact (1996)',\n",
       " '1351    Star Trek VI: The Undiscovered Country (1991)',\n",
       " '108    Braveheart (1995)',\n",
       " '1851    Small Soldiers (1998)',\n",
       " '1505    Lost World: Jurassic Park, The (1997)']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars = lambda item_id, sim : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                        for x in reversed(np.argsort(sim[item_id,:])[-10:])]\n",
    "\n",
    "get_similars(2628, cosine_similarity(warp_trained.item_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " '2618    Tarzan (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '584    Aladdin (1992)',\n",
       " '591    Beauty and the Beast (1991)',\n",
       " '1526    Hercules (1997)',\n",
       " '12    Balto (1995)',\n",
       " '33    Babe (1995)',\n",
       " '592    Pinocchio (1940)']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, cosine_similarity(warp_trained.item_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3402    Close Encounters of the Third Kind (1977)',\n",
       " '2875    Dirty Dozen, The (1967)',\n",
       " '1568    Hunt for Red October, The (1990)',\n",
       " '1230    Bridge on the River Kwai, The (1957)',\n",
       " '1214    Boat, The (Das Boot) (1981)',\n",
       " '1204    Full Metal Jacket (1987)',\n",
       " '1203    Godfather: Part II, The (1974)',\n",
       " '1190    Apocalypse Now (1979)',\n",
       " '1182    Aliens (1986)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, warp_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
